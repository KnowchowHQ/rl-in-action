{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cv9hgPks9LhM"
   },
   "source": [
    "# Reinforcement learning with Foolsball\n",
    "- Reinforcement learning is learning to make decisions from experience.\n",
    "- Games are a good testbed for RL.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWEnCb0m9ve8"
   },
   "source": [
    "# About Foolsball v3.0\n",
    "- 5x4 playground that provides a football/foosball-like environment.\n",
    "- A controllable player:\n",
    "  - always spawned in the top-left corner\n",
    "  - displayed as '⚽'\n",
    "  - can move North, South, East or West.\n",
    "  - **Movements have some uncertainty associated with them.**\n",
    "  - can be controlled algorithmically\n",
    "- A number of **dynamic** opponents, each represented by 👕, that occupy certain locations on the field.\n",
    "- **The opponents can move up or down randomly independent of each other**\n",
    "- A goalpost 🥅 that is fixed in the bottom right corner\n",
    "\n",
    "## Goals\n",
    "### Primary goal\n",
    "- We want the agent to learn to reach the goalpost \n",
    "\n",
    "### Secondary goals\n",
    "- We may want the agent to learn to be efficient in some sense, for example, take the shortest path to the goalpost. \n",
    "\n",
    "## Rules \n",
    "- Initial rules:\n",
    "    - **The ball can be (tried to be) moved in five ways: \\['n','e','w',s','x'\\], 'x' representing holding the ball in the current position.**\n",
    "    - **When a direction is selected to move the ball to a desired position, the ball can actually slip and move to a position different from the intended position.**\n",
    "    - Move the ball to an unmarked position: -1 points\n",
    "    - Move the ball to a position marked by a defender: -5 points\n",
    "    - Try to move the ball ouside the field: -1 (ball stays in the previous position)\n",
    "    - Move the ball into the goal post position: +5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "agent = '⚽'\n",
    "opponent = '👕'\n",
    "goal = '🥅'\n",
    "\n",
    "arena = [['⚽', ' ' , '👕', ' ' ],\n",
    "         [' ' , ' ' , ' ' , '👕'],\n",
    "         [' ' , '👕', ' ' , ' ' ],\n",
    "         [' ' , ' ' , ' ' , '👕'],\n",
    "         [' ' , '👕', ' ' , '🥅']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "class Foolsball(object):\n",
    "    def __to_state__(self,row,col):\n",
    "        \"\"\"Convert from indices (row,col) to integer position.\"\"\"\n",
    "        return row*self.n_cols + col\n",
    "    \n",
    "    \n",
    "    def __to_indices__(self, state):\n",
    "        \"\"\"Convert from inteeger position to indices(row,col)\"\"\"\n",
    "        row = state // self.n_cols\n",
    "        col = state % self.n_cols\n",
    "        return row,col\n",
    "\n",
    "    def __deserialize__(self,map:list,agent:str,opponent:str, goal:str):\n",
    "        \"\"\"Convrt a string representation of a map into a 2D numpy array\n",
    "        Param map: list of lists of strings representing the player, opponents and goal.\n",
    "        Param agent: string representing the agent on the map \n",
    "        Param opponent: string representing every instance of an opponent player\n",
    "        Param goal: string representing the location of the goal on the map\n",
    "        \"\"\"\n",
    "        ## Capture dimensions and map.\n",
    "        self.n_rows = len(map)\n",
    "        self.n_cols = len(map[0])\n",
    "        self.n_states = self.n_rows * self.n_cols\n",
    "        self.map = np.asarray(map)\n",
    "\n",
    "        ## Store string representations for printing the map, etc.\n",
    "        self.agent_repr = agent\n",
    "        self.opponent_repr  = opponent\n",
    "        self.goal_repr = goal\n",
    "\n",
    "        ## Find initial state, the desired goal state and the state of the opponents. \n",
    "        self.init_state = None\n",
    "        self.goal_state = None\n",
    "        self.opponents_states = []\n",
    "\n",
    "        for row in range(self.n_rows):\n",
    "            for col in range(self.n_cols):\n",
    "                if map[row][col] == agent:\n",
    "                    # Store the initial state outside the map.\n",
    "                    # This helps in quickly resetting the game to the initial state and\n",
    "                    # also simplifies printing the map independent of the agent's state. \n",
    "                    self.init_state = self.__to_state__(row,col)\n",
    "                    self.map[row,col] = ' ' \n",
    "\n",
    "                elif map[row][col] == opponent:\n",
    "                    self.opponents_states.append(self.__to_state__(row,col))\n",
    "\n",
    "                elif map[row][col] == goal:\n",
    "                    self.goal_state = self.__to_state__(row,col)\n",
    "\n",
    "        assert self.init_state is not None, f\"Map {map} does not specify an agent {agent} location\"\n",
    "        assert self.goal_state is not None,  f\"Map {map} does not specify a goal {goal} location\"\n",
    "        assert self.opponents_states,  f\"Map {map} does not specify any opponents {opponent} location\"\n",
    "\n",
    "        return self.init_state\n",
    "    \n",
    "    \n",
    "    def __init__(self,map,agent,opponent,goal,slip_prob=0):\n",
    "        \"\"\"Spawn the world, create variables to track state and actions.\"\"\"\n",
    "        # We just need to track the location of the agent (the ball)\n",
    "        # Everything else is static and so a potential algorithm doesn't \n",
    "        # have to look at it. The variable `done` flags terminal states.\n",
    "        self.state = self.__deserialize__(map,agent,opponent,goal)\n",
    "        self.done = False\n",
    "        self.actions = ['n','e','w','s','x']\n",
    "        self.n_actions = len(self.actions)\n",
    "        \n",
    "        self.__set_state_transitions__(slip_prob)\n",
    "\n",
    "        # Set up the rewards\n",
    "        self.default_rewards = {'hold':-1, 'unmarked':-1, 'opponent':-5, 'outside':-1, 'goal':+5}\n",
    "        self.set_rewards(self.default_rewards)\n",
    "        \n",
    "    def set_rewards(self,rewards):\n",
    "        if not self.state == self.init_state:\n",
    "            print('Warning: Setting reward while not in initial state! You may want to call reset() first.')\n",
    "        for key in self.default_rewards:\n",
    "            assert key in rewards, f'Key {key} missing from reward.'\n",
    "        self.rewards = rewards\n",
    "            \n",
    "            \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the environment to its initial state.\"\"\"\n",
    "        # There's really just two things we need to reset: the state, which should\n",
    "        # be reset to the initial state, and the `done` flag which should be \n",
    "        # cleared to signal that we are not in a terminal state anymore, even if we \n",
    "        # were earlier. \n",
    "        self.state = self.init_state\n",
    "        self.done  = False\n",
    "        return self.state\n",
    "    \n",
    "    def __get_likely_next_state_on_action__(self,state,action):\n",
    "        \"\"\"Return next state based on current state and deterministic action.\"\"\"\n",
    "        assert not self.__is_terminal_state__(state), f\"Action {action} undefined for terminal state {state}\"\n",
    "        \n",
    "        row, col = self.__to_indices__(state)\n",
    "        action_to_index_delta = {'n':[-1,0], 'e':[0,+1], 'w':[0,-1], 's':[+1,0], 'x':[0,0]}\n",
    "\n",
    "        row_delta, col_delta = action_to_index_delta[action]\n",
    "        new_row , new_col = row+row_delta, col+col_delta\n",
    "\n",
    "        ## Return current state if next state is invalid\n",
    "        if not(0<=new_row<self.n_rows) or\\\n",
    "        not(0<=new_col<self.n_cols):\n",
    "            return state  \n",
    "\n",
    "        ## Construct state from new row and col and return it.    \n",
    "        return self.__to_state__(new_row, new_col)   \n",
    "    \n",
    "    \n",
    "    def __get_next_state_on_action__(self,state,action):\n",
    "        \"\"\"Return next state based on current state and deterministic action.\"\"\"\n",
    "        assert not self.__is_terminal_state__(state), f\"Action {action} undefined for terminal state {state}\"\n",
    "        \n",
    "        action_index = self.actions.index(action)\n",
    "        next_state = np.random.choice(list(range(self.n_states)),p=self.P[state,action_index])\n",
    "        return next_state\n",
    "\n",
    "    \n",
    "  \n",
    "    def __get_reward_for_transition__(self,state,next_state):\n",
    "        \"\"\" Return the reward based on the transition from current state to next state. \"\"\"\n",
    "        ## Transition rejected due to illegal action (move)\n",
    "        assert not self.__is_terminal_state__(state), f\"Reward is undefined for terminal state {state}\"\n",
    "        \n",
    "        if next_state == state:\n",
    "            reward = self.rewards['outside']\n",
    "\n",
    "        ## Goal!\n",
    "        elif next_state == self.goal_state:\n",
    "            reward = self.rewards['goal']\n",
    "\n",
    "        ## Ran into opponent. \n",
    "        elif next_state in self.opponents_states:\n",
    "            reward = self.rewards['opponent']\n",
    "\n",
    "        ## Made a safe and valid move.   \n",
    "        else:\n",
    "            reward = self.rewards['unmarked']\n",
    "\n",
    "        return reward    \n",
    "    \n",
    "    \n",
    "    def __is_terminal_state__(self, state):\n",
    "        return (state == self.goal_state) or (state in self.opponents_states) \n",
    "    \n",
    "      \n",
    "    def step(self,action):\n",
    "        \"\"\"Simulate state transition based on current state and action received.\"\"\"\n",
    "        assert not self.done, \\\n",
    "        f'You cannot call step() in a terminal state({self.state}). Check the \"done\" flag before calling step() to avoid this.'\n",
    "        next_state = self.__get_next_state_on_action__(self.state, action)\n",
    "\n",
    "        reward = self.__get_reward_for_transition__(self.state, next_state)\n",
    "\n",
    "        done = self.__is_terminal_state__(next_state)\n",
    "\n",
    "        self.state, self.done = next_state, done\n",
    "\n",
    "        return next_state, reward, done\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __set_state_transitions__(self,prob_slip):\n",
    "        self.P = np.zeros([self.n_states, self.n_actions, self.n_states])\n",
    "        \n",
    "        #pdb.set_trace()\n",
    "        for state in range(self.n_states):\n",
    "            if not self.__is_terminal_state__(state):\n",
    "                for action_index in range(self.n_actions):\n",
    "                    for bad_action_index in range(self.n_actions):\n",
    "                        if action_index == bad_action_index:\n",
    "                            next_state = self.__get_likely_next_state_on_action__(state,self.actions[action_index])\n",
    "                            self.P[state,action_index,next_state] += 1-prob_slip\n",
    "                            #print(f'state:{state},action:{action_index},bad_action:{bad_action_index},next_state:{next_state},prob:{self.P[state,action_index,next_state]}')\n",
    "                        else:\n",
    "                            next_state = self.__get_likely_next_state_on_action__(state,self.actions[bad_action_index])\n",
    "                            self.P[state,action_index, next_state] += prob_slip/(self.n_actions-1)\n",
    "                            #print(f'state:{state},action:{action_index},bad_action:{bad_action_index},next_state:{next_state},prob:{self.P[state,action_index,next_state]}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"Pretty-print the environment and agent.\"\"\"\n",
    "        ## Create a copy of the map and change data type to accomodate\n",
    "        ## 3-character strings\n",
    "        _map = np.array(self.map, dtype='<U3')\n",
    "\n",
    "        ## Mark unoccupied positions with special symbol.\n",
    "        ## And add extra spacing to align all columns.\n",
    "        for row in range(_map.shape[0]):\n",
    "            for col in range(_map.shape[1]):\n",
    "                if _map[row,col] == ' ':\n",
    "                    _map[row,col] = ' + '\n",
    "\n",
    "                elif _map[row,col] == self.opponent_repr: \n",
    "                    _map[row,col] =  self.opponent_repr + ' '\n",
    "\n",
    "                elif _map[row,col] == self.goal_repr:\n",
    "                    _map[row,col] = ' ' + self.goal_repr + ' '\n",
    "\n",
    "        ## If current state overlaps with the goal state or one of the opponents'\n",
    "        ## states, susbstitute a distinct marker.\n",
    "        if self.state == self.goal_state:\n",
    "            r,c = self.__to_indices__(self.state)\n",
    "            _map[r,c] = ' 🏁 '\n",
    "        elif self.state in self.opponents_states:\n",
    "            r,c = self.__to_indices__(self.state)\n",
    "            _map[r,c] = ' ❗ '\n",
    "        else:\n",
    "            r,c = self.__to_indices__(self.state)\n",
    "            _map[r,c] = ' ' + self.agent_repr\n",
    "\n",
    "        for row in range(_map.shape[0]):\n",
    "            for col in range(_map.shape[1]):\n",
    "                print(f' {_map[row,col]} ',end=\"\")\n",
    "            print('\\n') \n",
    "\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "foolsball = Foolsball(arena, agent, opponent, goal, slip_prob=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foolsball.P.sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5nn8RNR1NDZK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ⚽   +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "foolsball.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interact with the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, -5, True)\n",
      "\n",
      "  +    +    ❗    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "  ⚽   +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(4, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  ⚽   +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(5, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    ⚽   +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(6, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    ⚽  👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(10, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    ⚽   +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(14, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    ⚽  👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(18, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    ⚽   🥅  \n",
      "\n",
      "\n",
      "(19, 5, True)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🏁  \n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "  ⚽   +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(1, -1, False)\n",
      "\n",
      "  +    ⚽  👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(1, -1, False)\n",
      "\n",
      "  +    ⚽  👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(0, -1, False)\n",
      "\n",
      "  ⚽   +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(4, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  ⚽   +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(8, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  ⚽  👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(12, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  ⚽   +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(16, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  ⚽  👕    +    🥅  \n",
      "\n",
      "\n",
      "(12, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  ⚽   +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(13, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    ⚽   +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(14, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    ⚽  👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(10, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    ⚽   +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(11, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    ⚽ \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(10, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    ⚽   +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(14, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    ⚽  👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(18, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    ⚽   🥅  \n",
      "\n",
      "\n",
      "(14, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    ⚽  👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(13, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    ⚽   +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(14, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    ⚽  👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(18, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    ⚽   🥅  \n",
      "\n",
      "\n",
      "(14, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    ⚽  👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(18, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    ⚽   🥅  \n",
      "\n",
      "\n",
      "(14, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    ⚽  👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(18, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    ⚽   🥅  \n",
      "\n",
      "\n",
      "(14, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    ⚽  👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(18, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    ⚽   🥅  \n",
      "\n",
      "\n",
      "(14, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    ⚽  👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(18, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    ⚽   🥅  \n",
      "\n",
      "\n",
      "(14, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    ⚽  👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(18, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    ⚽   🥅  \n",
      "\n",
      "\n",
      "(14, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    ⚽  👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(10, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    ⚽   +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(6, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    ⚽  👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(10, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    ⚽   +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(14, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    ⚽  👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(13, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    ⚽   +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(12, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  ⚽   +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(12, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  ⚽   +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(12, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  ⚽   +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(12, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  ⚽   +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(16, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  ⚽  👕    +    🥅  \n",
      "\n",
      "\n",
      "(12, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  ⚽   +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(13, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    ⚽   +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(14, -1, False)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    ⚽  👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "(15, -5, True)\n",
      "\n",
      "  +    +   👕    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +    ❗  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Move: n,s,e,w\n",
    "## Reset: r\n",
    "## Exit: x\n",
    "while True:\n",
    "    try:\n",
    "        act = input('>>')\n",
    "\n",
    "        if act in foolsball.actions:\n",
    "            print(foolsball.step(act))\n",
    "            print()\n",
    "            foolsball.render()\n",
    "        elif act == 'r':\n",
    "            print(foolsball.reset())\n",
    "            print()\n",
    "            foolsball.render()\n",
    "        elif act == 'x':\n",
    "            break\n",
    "        else:\n",
    "            print(f'Invalid input:{act}')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Override the default reward structure.\n",
    "- Use a more sparse reward: {'unmarked':0, 'opponent':-5, 'outside':-1, 'goal':+5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update reward structure to: {'unmarked':0, 'opponent':-5, 'outside':-1, 'goal':+5}\n",
    "foolsball.reset()\n",
    "foolsball.set_rewards({'unmarked':0, 'opponent':-5, 'outside':-1, 'goal':+5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement discounted returns¶\n",
    "$$Discounted\\ Return = R_{t_1} + \\gamma*R_{t_2} + \\gamma^2*R_{t_3} + ... + \\gamma^{n-1}*R_{t_n}$$where $R_{t_k}$ is the reward after step k and $\\gamma$ is called the discount factor.\n",
    "- Set the discount factor $\\gamma$ to 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discounted_return(path, gamma=0):\n",
    "    foolsball.reset()\n",
    "    foolsball.render()\n",
    "    _return_ = 0\n",
    "    discount_coeff = 1\n",
    "    for act in path: \n",
    "        next_state, reward, done = foolsball.step(act)\n",
    "        _return_ += discount_coeff*reward\n",
    "        discount_coeff *= gamma    \n",
    "\n",
    "        foolsball.render()\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    print(f'Return (accumulated reward): {_return_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPER_PARAMS = {'gamma':0.9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_policy_from_returns_tbl(table):\n",
    "    policy = {s:None for s in table.index }\n",
    "    terminal_states = foolsball.opponents_states + [foolsball.goal_state]\n",
    "    for state in table.index:\n",
    "        if state not in terminal_states:\n",
    "            greedy_action = table.loc[state].idxmax()\n",
    "            policy[state] = greedy_action\n",
    "            \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_policy(policy):\n",
    "    direction_repr = {'n':' 🡑 ', 'e':' 🡒 ', 'w':' 🡐 ', 's':' 🡓 ', None:' ⬤ '}\n",
    "\n",
    "    for row in range(foolsball.n_rows):\n",
    "        for col in range(foolsball.n_cols):\n",
    "            state = foolsball.__to_state__(row, col)\n",
    "            print(direction_repr[policy[state]],end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with incomplete Knowledge of the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def collect_random_episode():\n",
    "    state = foolsball.reset()\n",
    "    done = False\n",
    "    episode = []\n",
    "    \n",
    "    while not done:\n",
    "        action = np.random.choice(foolsball.actions)\n",
    "        next_state, reward, done = foolsball.step(action)\n",
    "        episode.append([state, action, reward])\n",
    "        state = next_state\n",
    "        \n",
    "    return episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  +    +    ❗    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    +  \n",
      "\n",
      "  +    +    +   👕  \n",
      "\n",
      "  +   👕    +    🥅  \n",
      "\n",
      "\n",
      "[[0, 'e', 0], [1, 'n', -1], [1, 's', 0], [5, 'e', 0], [6, 'n', -5]]\n"
     ]
    }
   ],
   "source": [
    "ep = collect_random_episode()\n",
    "foolsball.render()\n",
    "print(ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement discounted returns for episodes\n",
    "- If an episode is: (s1,a1,r1),(s2,a2,r2),(s3,a3,r3), (s4),  s4 being a terminal state:\n",
    "  - The (discounted) return for (s1,a1) is r1+γ∗r2+γ2∗r3\n",
    "  - The (discounted) return for (s2, a2)is r2+γ∗r3\n",
    "  - The (discounted) return for (s3,a3) is r3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discounted_return_from_episode(ep, gamma=0):\n",
    "    states, actions, rewards = list(zip(*ep))\n",
    "    rewards = np.asarray(rewards)\n",
    "    discount_coeffs = np.asarray([np.power(gamma,p) for p in range(len(rewards))])\n",
    "    \n",
    "    l = len(rewards)\n",
    "    discounted_returns = [np.dot(rewards[i:],discount_coeffs[:l-i]) for i in range(l)]\n",
    "    \n",
    "    return (states, actions, discounted_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1, 1, 5, 6),\n",
       " ('e', 'n', 's', 'e', 'n'),\n",
       " [-4.1805, -4.6450000000000005, -4.050000000000001, -4.5, -5.0])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discounted_return_from_episode(ep, gamma=HYPER_PARAMS['gamma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration-Exploitation with Epsilon Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_epsilon_greedy_episode_from_returns_tbl(table, max_ep_len=20, epsilon=0.1):\n",
    "    state = foolsball.reset()\n",
    "    done = False\n",
    "    episode = []\n",
    "    \n",
    "    for _ in range(max_ep_len):\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "        actions = table.columns\n",
    "        action_probs = np.asarray([epsilon/len(actions)]*len(actions),dtype=np.float)\n",
    "\n",
    "        greedy_action_index = np.argmax(table.loc[state].values)\n",
    "        action_probs[greedy_action_index] += 1-epsilon\n",
    "\n",
    "        epsilon_greedy_action = np.random.choice(table.columns,p=action_probs)\n",
    "\n",
    "        next_state, reward, done = foolsball.step(epsilon_greedy_action)\n",
    "        episode.append([state, epsilon_greedy_action, reward])\n",
    "        state = next_state\n",
    "\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant Alpha\n",
    "\n",
    "## The idea:\n",
    "- Dividing the accumulated returns by visit count has a non linear effect on the updates. (Go back to previous step and see for yourself).\n",
    "- Don't divide at all!\n",
    "- But we need to ensure that updates are small\n",
    "- Idea:\n",
    " - ESTIMATED_RETURNS_TBL.loc[s,a] and ret are both estimates of the same quantity.\n",
    " - Use the difference of the two estimates to update ESTIMATED_RETURNS_TBL.loc[s,a] much like we do in Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ESTIMATED_RETURNS_TBL = pd.DataFrame.from_dict({s:{a:0 for a in foolsball.actions} for s in range(foolsball.n_states)}, orient='index')\n",
    "\n",
    "n_episodes = 5000\n",
    "epsilon = 1\n",
    "min_epsilon = 0.1\n",
    "epsilon_decay = 0.999\n",
    "\n",
    "alpha = 0.001\n",
    "\n",
    "for i in range(n_episodes):\n",
    "    estimated_returns = ESTIMATED_RETURNS_TBL\n",
    "  \n",
    "    epsilon = max(epsilon,min_epsilon)\n",
    "    episode_i = collect_epsilon_greedy_episode_from_returns_tbl(estimated_returns,epsilon=epsilon)\n",
    "    epsilon *= epsilon_decay\n",
    "    states, actions, discounted_returns = discounted_return_from_episode(episode_i, gamma=HYPER_PARAMS['gamma'])\n",
    "\n",
    "    for s,a,ret in zip(states, actions, discounted_returns):\n",
    "        ESTIMATED_RETURNS_TBL.loc[s,a] += alpha*(ret - ESTIMATED_RETURNS_TBL.loc[s,a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           n         e         w         s\n",
      "0  -1.660970 -1.542114 -1.563211  0.246278\n",
      "1  -0.987093 -1.054276 -0.804984 -0.973417\n",
      "2   0.000000  0.000000  0.000000  0.000000\n",
      "3   0.000000  0.000000  0.000000  0.000000\n",
      "4  -1.004597 -1.025197 -1.131975  0.438982\n",
      "5  -0.737691 -0.724179 -0.462921 -0.822774\n",
      "6  -0.271082 -0.285699 -0.241289 -0.252264\n",
      "7   0.000000  0.000000  0.000000  0.000000\n",
      "8  -0.559966 -1.083087 -0.621809  0.823008\n",
      "9   0.000000  0.000000  0.000000  0.000000\n",
      "10 -0.083517 -0.100502 -0.149559  0.276655\n",
      "11 -0.054726 -0.053723 -0.043019 -0.063274\n",
      "12 -0.168039  1.329605 -0.302638 -0.300402\n",
      "13 -0.735113  2.021769  0.022052 -0.699859\n",
      "14 -0.000926 -0.572435  0.082716  3.217014\n",
      "15  0.000000  0.000000  0.000000  0.000000\n",
      "16 -0.008496 -0.233499 -0.278689 -0.271581\n",
      "17  0.000000  0.000000  0.000000  0.000000\n",
      "18  0.242447  4.240127 -0.429892  0.247379\n",
      "19  0.000000  0.000000  0.000000  0.000000\n",
      "{0: 's', 1: 'w', 2: None, 3: 'n', 4: 's', 5: 'w', 6: 'w', 7: None, 8: 's', 9: None, 10: 's', 11: 'w', 12: 'e', 13: 'e', 14: 's', 15: None, 16: 'n', 17: None, 18: 'e', 19: None}\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡐  🡐  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    }
   ],
   "source": [
    "estimated_returns = ESTIMATED_RETURNS_TBL\n",
    "print(estimated_returns)\n",
    "\n",
    "policy0 = greedy_policy_from_returns_tbl(estimated_returns)\n",
    "print(policy0)\n",
    "\n",
    "pretty_print_policy(policy0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can we get faster convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try the SARSA and Q-learning appraches described [here](https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html#sarsa-on-policy-td-control) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Difference(TD) Learning\n",
    " - Learn every step of an episode \n",
    " - This translates into using an updated policy for selecting the action at each step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_action_from_Q(Q, state, epsilon):\n",
    "    actions = Q.columns\n",
    "    action_probs = np.asarray([epsilon/len(actions)]*len(actions),dtype=np.float)\n",
    "    \n",
    "    greedy_action_index = np.argmax(Q.loc[state].values)\n",
    "    action_probs[greedy_action_index] += 1-epsilon\n",
    "\n",
    "    epsilon_greedy_action = np.random.choice(Q.columns,p=action_probs)\n",
    "    \n",
    "    return epsilon_greedy_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARSA (State-Action-Reward-State-Action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 537/2000 [00:02<00:06, 210.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500\n",
      " 🡓  🡓  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡒  🡐 \n",
      " 🡒  🡐  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1048/2000 [00:04<00:04, 217.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000\n",
      " 🡓  🡓  ⬤  🡑 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡒  🡐 \n",
      " 🡒  🡐  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1535/2000 [00:07<00:02, 215.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1500\n",
      " 🡓  🡓  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:09<00:00, 210.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡐  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n",
      "{0: 's', 1: 'w', 2: None, 3: 'n', 4: 's', 5: 'w', 6: 's', 7: None, 8: 's', 9: None, 10: 's', 11: 'w', 12: 'e', 13: 'e', 14: 's', 15: None, 16: 'n', 17: None, 18: 'e', 19: None}\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡐  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "Q = pd.DataFrame.from_dict({s:{a:0 for a in foolsball.actions} for s in range(foolsball.n_states)}, orient='index')\n",
    "\n",
    "n_episodes = 2000\n",
    "epsilon = 1\n",
    "min_epsilon = 0.1\n",
    "epsilon_decay = 0.9995\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "\n",
    "for i in tqdm(range(n_episodes)):\n",
    "    foolsball.reset()\n",
    "    s0 = foolsball.init_state\n",
    "    a0 = epsilon_greedy_action_from_Q(Q,s0,epsilon)\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        s1, reward, done  = foolsball.step(a0)\n",
    "        a1 = epsilon_greedy_action_from_Q(Q,s1,epsilon)\n",
    "        \n",
    "        Q.loc[s0,a0] += alpha*(reward + HYPER_PARAMS['gamma']*Q.loc[s1,a1] - Q.loc[s0,a0])\n",
    "        \n",
    "        s0, a0 = s1, a1\n",
    "  \n",
    "    epsilon *= epsilon_decay\n",
    "    epsilon = max(epsilon,min_epsilon)\n",
    "    \n",
    "    if (i+1)%500 == 0:\n",
    "        print(f'Iteration {i+1}')\n",
    "        policy = greedy_policy_from_returns_tbl(Q)\n",
    "        pretty_print_policy(policy)\n",
    "        \n",
    "\n",
    "policy_SARSA = greedy_policy_from_returns_tbl(Q)\n",
    "print(policy_SARSA)\n",
    "\n",
    "pretty_print_policy(policy_SARSA)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 527/10000 [00:03<01:00, 157.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡐  🡓  ⬤ \n",
      " 🡑  ⬤  🡑  🡐 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡑  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1016/10000 [00:06<00:56, 157.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡐  🡐  ⬤ \n",
      " 🡓  ⬤  🡒  🡐 \n",
      " 🡑  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1549/10000 [00:11<01:01, 137.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1500\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡑  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2034/10000 [00:14<00:55, 143.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2524/10000 [00:16<00:50, 149.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2500\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3046/10000 [00:19<00:45, 154.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3000\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 3520/10000 [00:22<00:41, 157.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3500\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4035/10000 [00:25<00:37, 159.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4000\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4552/10000 [00:28<00:33, 161.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4500\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5021/10000 [00:30<00:30, 164.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5000\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 5529/10000 [00:33<00:26, 166.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5500\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 6058/10000 [00:35<00:23, 169.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6000\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6522/10000 [00:37<00:20, 171.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6500\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7041/10000 [00:40<00:16, 174.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7000\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 7539/10000 [00:43<00:14, 174.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7500\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8032/10000 [00:45<00:11, 175.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8000\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 8525/10000 [00:48<00:08, 175.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8500\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9029/10000 [00:51<00:05, 176.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9000\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 9523/10000 [00:53<00:02, 177.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9500\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:56<00:00, 178.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10000\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n",
      "{0: 's', 1: 'w', 2: None, 3: 'n', 4: 's', 5: 'e', 6: 's', 7: None, 8: 's', 9: None, 10: 's', 11: 'w', 12: 'e', 13: 'e', 14: 's', 15: None, 16: 'n', 17: None, 18: 'e', 19: None}\n",
      " 🡓  🡐  ⬤  🡑 \n",
      " 🡓  🡒  🡓  ⬤ \n",
      " 🡓  ⬤  🡓  🡐 \n",
      " 🡒  🡒  🡓  ⬤ \n",
      " 🡑  ⬤  🡒  ⬤ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "Q = pd.DataFrame.from_dict({s:{a:0 for a in foolsball.actions} for s in range(foolsball.n_states)}, orient='index')\n",
    "\n",
    "n_episodes = 10000\n",
    "epsilon = 1\n",
    "min_epsilon = 0.1\n",
    "epsilon_decay = 0.9995\n",
    "\n",
    "alpha = 0.01\n",
    "rewards = np.zeros(n_episodes)\n",
    "\n",
    "\n",
    "for i in tqdm(range(n_episodes)):\n",
    "    foolsball.reset()\n",
    "    s0 = foolsball.init_state\n",
    "    done = False\n",
    "    \n",
    "    episode_reward = 0\n",
    "    while not done:\n",
    "        a0 = epsilon_greedy_action_from_Q(Q,s0,epsilon)\n",
    "        s1, reward, done  = foolsball.step(a0)\n",
    "        \n",
    "        Q.loc[s0,a0] += alpha*(reward + HYPER_PARAMS['gamma']*Q.loc[s1].max() - Q.loc[s0,a0])\n",
    "        episode_reward += reward\n",
    "        \n",
    "        s0 = s1\n",
    "  \n",
    "    epsilon *= epsilon_decay\n",
    "    epsilon = max(epsilon,min_epsilon)\n",
    "    \n",
    "    rewards[i] = episode_reward\n",
    "    \n",
    "    if (i+1)%500 == 0:\n",
    "        print(f'Iteration {i+1}')\n",
    "        policy = greedy_policy_from_returns_tbl(Q)\n",
    "        pretty_print_policy(policy)\n",
    "        #print(Q)\n",
    "        \n",
    "\n",
    "policy_Q_Learning = greedy_policy_from_returns_tbl(Q)\n",
    "print(policy_Q_Learning)\n",
    "\n",
    "pretty_print_policy(policy_Q_Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>e</th>\n",
       "      <th>w</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.150929</td>\n",
       "      <td>0.586226</td>\n",
       "      <td>0.165312</td>\n",
       "      <td>1.381327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.227858</td>\n",
       "      <td>-4.381477</td>\n",
       "      <td>0.966672</td>\n",
       "      <td>-0.459430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.052189</td>\n",
       "      <td>0.738371</td>\n",
       "      <td>0.379756</td>\n",
       "      <td>1.644754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.334575</td>\n",
       "      <td>1.216929</td>\n",
       "      <td>-0.313740</td>\n",
       "      <td>-4.461178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2.979192</td>\n",
       "      <td>-3.415245</td>\n",
       "      <td>-0.184548</td>\n",
       "      <td>2.003168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.935133</td>\n",
       "      <td>-4.394334</td>\n",
       "      <td>0.392220</td>\n",
       "      <td>1.888973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.093905</td>\n",
       "      <td>-0.198023</td>\n",
       "      <td>-2.189636</td>\n",
       "      <td>2.852078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.797302</td>\n",
       "      <td>-0.215014</td>\n",
       "      <td>0.674660</td>\n",
       "      <td>-0.599660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.504277</td>\n",
       "      <td>2.474426</td>\n",
       "      <td>1.122178</td>\n",
       "      <td>1.260310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-4.334804</td>\n",
       "      <td>2.929506</td>\n",
       "      <td>1.337699</td>\n",
       "      <td>-4.479649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.954269</td>\n",
       "      <td>-4.194131</td>\n",
       "      <td>1.971147</td>\n",
       "      <td>3.879504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.703228</td>\n",
       "      <td>-3.211025</td>\n",
       "      <td>-0.782178</td>\n",
       "      <td>-0.689446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.714287</td>\n",
       "      <td>4.594961</td>\n",
       "      <td>-3.922640</td>\n",
       "      <td>2.765543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           n         e         w         s\n",
       "0   0.150929  0.586226  0.165312  1.381327\n",
       "1  -1.227858 -4.381477  0.966672 -0.459430\n",
       "2   0.000000  0.000000  0.000000  0.000000\n",
       "3   0.000000  0.000000  0.000000  0.000000\n",
       "4   1.052189  0.738371  0.379756  1.644754\n",
       "5  -0.334575  1.216929 -0.313740 -4.461178\n",
       "6  -2.979192 -3.415245 -0.184548  2.003168\n",
       "7   0.000000  0.000000  0.000000  0.000000\n",
       "8   0.935133 -4.394334  0.392220  1.888973\n",
       "9   0.000000  0.000000  0.000000  0.000000\n",
       "10  0.093905 -0.198023 -2.189636  2.852078\n",
       "11 -0.797302 -0.215014  0.674660 -0.599660\n",
       "12  1.504277  2.474426  1.122178  1.260310\n",
       "13 -4.334804  2.929506  1.337699 -4.479649\n",
       "14  1.954269 -4.194131  1.971147  3.879504\n",
       "15  0.000000  0.000000  0.000000  0.000000\n",
       "16  1.703228 -3.211025 -0.782178 -0.689446\n",
       "17  0.000000  0.000000  0.000000  0.000000\n",
       "18  2.714287  4.594961 -3.922640  2.765543\n",
       "19  0.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "windowed_rewards = np.convolve(rewards, np.ones(100), 'valid')\n",
    "plt.plot(windowed_rewards/100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Rediscovering_RL_Notebook_0_SOLVED.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
